{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a3ea2a-e6a4-41ed-9e4e-8a3d629ab445",
   "metadata": {},
   "source": [
    "#### Helpful links\n",
    "####  https://github.com/Reagan0914/DInSAR_Processing_Snappy/blob/master/DataProcessing/S1_SLC_Processing.py\n",
    "#### https://www.youtube.com/watch?v=PiU68g3WRIY&t=1498s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17c10e",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354f641-ecd5-481b-9613-21ea98e6fc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import snappy_esa\n",
    "from snappy_esa import ProductIO\n",
    "from snappy_esa import GPF\n",
    "from snappy_esa import HashMap\n",
    "from snappy_esa import jpy\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from multiprocessing import Process\n",
    "import pandas as pd\n",
    "import csv\n",
    "from os.path import join \n",
    "from glob import iglob\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cda867-75ce-4dfb-b300-d3a40f93060d",
   "metadata": {},
   "source": [
    "## Definition\n",
    "Introduction:\n",
    " This script contains functions to perform various operations on Sentinel-1 SAR (Synthetic Aperture Radar) products.\n",
    " These operations include data manipulation, processing, and correction to prepare the data for further analysis.\n",
    "\n",
    "### Description:\n",
    " The script defines functions to perform the following operations:\n",
    " - Reading and writing Sentinel-1 SAR products.\n",
    " - Splitting TOPSAR data into subswaths.\n",
    " - Assembling slices of TOPSAR data.\n",
    " - Combining multiple products.\n",
    " - Applying orbit files for precise orbit information.\n",
    " - Back-geocoding to correct geometric distortions.\n",
    " - Calculating enhanced spectral diversity.\n",
    " - Generating interferograms.\n",
    " - Debursting TOPSAR data.\n",
    " - Performing terrain correction to project data onto a common coordinate reference system.\n",
    " Each function takes input parameters, applies processing steps using the SNAP (Sentinel Application Platform) toolbox, and returns the processed product.\n",
    "\n",
    " Usage:\n",
    " Users can call these functions individually or combine them to create custom processing pipelines for Sentinel-1 SAR data.\n",
    " For example, they can read data, perform terrain correction, and then generate interferograms for interferometric analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d62aad-2190-4f94-b250-55a722d6a804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HashMap = jpy.get_type('java.util.HashMap')\n",
    "\n",
    "parameters = HashMap()\n",
    "\n",
    "def read(filename):\n",
    "    return ProductIO.readProduct(filename)\n",
    "\n",
    "def write(product, filename, format=None):\n",
    "    return ProductIO.writeProduct(product, filename, format if format else \"GeoTIFF\")\n",
    "\n",
    "def TOPSAR_split1(product, firstBurstIndex, lastBurstIndex):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('subswath', 'IW1')\n",
    "    parameters.put('selectedPolarisations', 'VV')\n",
    "    parameters.put('firstBurstIndex', firstBurstIndex)\n",
    "    parameters.put('lastBurstIndex', lastBurstIndex)\n",
    "    return GPF.createProduct('TOPSAR-Split', parameters, product)\n",
    "\n",
    "def TOPSAR_split2(product, firstBurstIndex, lastBurstIndex):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('subswath', 'IW2')\n",
    "    parameters.put('selectedPolarisations', 'VV')\n",
    "    parameters.put('firstBurstIndex', firstBurstIndex)\n",
    "    parameters.put('lastBurstIndex', lastBurstIndex)\n",
    "    return GPF.createProduct('TOPSAR-Split', parameters, product)\n",
    "\n",
    "def TOPSAR_split3(product, firstBurstIndex, lastBurstIndex):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('subswath', 'IW3')\n",
    "    parameters.put('selectedPolarisations', 'VV')\n",
    "    parameters.put('firstBurstIndex', firstBurstIndex)\n",
    "    parameters.put('lastBurstIndex', lastBurstIndex)\n",
    "    return GPF.createProduct('TOPSAR-Split', parameters, product)\n",
    "\n",
    "def Slice_Assembly(list_of_products):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('selectedPolarizations', 'VV')\n",
    "    return GPF.createProduct('SliceAssembly', parameters, list_of_products)\n",
    "\n",
    "def combine():\n",
    "    file1 = read(os.path.join(path_files_to_be_merged, files[0]))\n",
    "    file2 = read(os.path.join(path_files_to_be_merged, files[1]))\n",
    "    file3 = read(os.path.join(path_files_to_be_merged, files[2]))\n",
    "    merged_product = Slice_Assembly([TOPSAR_split1(file1, 1, 9), TOPSAR_split2(file2, 1, 9), TOPSAR_split3(file3, 1, 9)])\n",
    "    write(merged_product, os.path.join(output_dir, f\"S1_SLC_{files[0].split('_')[5][:8]}_{files[0].split('_')[-1][:-4]}_{files[2].split('_')[-1][:-4]}_Split_SplAmb\"))\n",
    "    return merged_product\n",
    "\n",
    "def apply_orbit_file(product):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('orbitType', 'Sentinel Precise (Auto Download)')\n",
    "    parameters.put('polyDegree', 3)\n",
    "    parameters.put('continueOnFail', True)\n",
    "    return GPF.createProduct('Apply-Orbit-File', parameters, product)\n",
    "\n",
    "def back_geocoding(product):    \n",
    "    parameters = HashMap()\n",
    "    parameters.put(\"Digital Elevation Model\", \"SRTM 1Sec HGT\")\n",
    "    parameters.put(\"DEM Resampling Method\", \"BICUBIC_INTERPOLATION\")\n",
    "    parameters.put(\"Resampling Type\", \"BISINC_5_POINT_INTERPOLATION\")\n",
    "    parameters.put(\"Mask out areas with no elevation\", True)\n",
    "    parameters.put(\"Output Deramp and Demod Phase\", True)    \n",
    "    return GPF.createProduct(\"Back-Geocoding\", parameters, product)\n",
    "\n",
    "def enhanced_spectral_diversity(product):\n",
    "    parameters = HashMap()\n",
    "    parameters.put(\"fineWinWidthStr\", \"512\")  \n",
    "    parameters.put(\"fineWinHeightStr\", \"512\") \n",
    "    parameters.put(\"fineWinAccAzimuth\", \"16\")  \n",
    "    parameters.put(\"fineWinAccRange\", \"16\")  \n",
    "    parameters.put(\"fineWinOversampling\", \"128\")  \n",
    "    parameters.put(\"xCorrThreshold\", \"0.1\")  \n",
    "    parameters.put(\"cohThreshold\", \"0.15\")  \n",
    "    parameters.put(\"numBlocksPerOverlap\", \"10\")  \n",
    "    parameters.put(\"useSuppliedRangeShift\", False)\n",
    "    parameters.put(\"overallRangeShift\", \"0.0\")  \n",
    "    parameters.put(\"useSuppliedAzimuthShift\", False)\n",
    "    parameters.put(\"overallAzimuthShift\", \"0.0\")  \n",
    "    return GPF.createProduct('Enhanced-Spectral-Diversity', parameters, product)\n",
    "\n",
    "def interferogram(product):\n",
    "    parameters = HashMap()  \n",
    "    parameters.put(\"Subtract flat-earth phase\", True)\n",
    "    parameters.put(\"Degree of \\\"Flat Earth\\\" polynomial\", 5)\n",
    "    parameters.put(\"Number of \\\"Flat Earth\\\" estimation points\", 501)\n",
    "    parameters.put(\"Orbit interpolation degree\", 3)\n",
    "    parameters.put(\"Include coherence estimation\", True)\n",
    "    parameters.put(\"Square Pixel\", True)\n",
    "    parameters.put(\"Independent Window Sizes\", False)\n",
    "    parameters.put(\"Coherence Azimuth Window Size\", 5)\n",
    "    parameters.put(\"Coherence Range Window Size\", 20)\n",
    "    return GPF.createProduct(\"Interferogram\", parameters, product)\n",
    "\n",
    "def topsar_deburst(product):\n",
    "    parameters = HashMap()\n",
    "    parameters.put('selectedPolarisations','VV')\n",
    "    return GPF.createProduct('TOPSAR-Deburst', parameters, product)\n",
    "\n",
    "def terrain_correction(src, projection):\n",
    "    parameters = HashMap()\n",
    "    parameters.put(\"demName\", \"SRTM 1Sec HGT\")  # ~25 to 30m\n",
    "    parameters.put(\"externalDEMNoDataValue\", 0.0)\n",
    "    parameters.put(\"externalDEMApplyEGM\", True)\n",
    "    parameters.put(\"demResamplingMethod\", \"BICUBIC_INTERPOLATION\")\n",
    "    parameters.put(\"imgResamplingMethod\", \"BICUBIC_INTERPOLATION\")\n",
    "    parameters.put(\"pixelSpacingInMeter\", 10.0)\n",
    "    parameters.put(\"pixelSpacingInDegree\", 8.983152841195215E-5)\n",
    "    parameters.put(\"mapProjection\", projection)\n",
    "    parameters.put(\"alignToStandardGrid\", False)\n",
    "    parameters.put(\"standardGridOriginX\", 0.0)\n",
    "    parameters.put(\"standardGridOriginY\", 0.0)\n",
    "    parameters.put(\"nodataValueAtSea\", True)\n",
    "    parameters.put(\"saveDEM\", False)\n",
    "    parameters.put(\"saveLatLon\", False)\n",
    "    parameters.put(\"saveIncidenceAngleFromEllipsoid\", False)\n",
    "    parameters.put(\"saveLocalIncidenceAngle\", False)\n",
    "    parameters.put(\"saveSelectedSourceBand\", True)\n",
    "    parameters.put(\"outputComplex\", False)\n",
    "    parameters.put(\"applyRadiometricNormalization\", False)\n",
    "    parameters.put(\"saveSigmaNought\", False)\n",
    "    parameters.put(\"saveGammaNought\", False)\n",
    "    parameters.put(\"saveBetaNought\", False)\n",
    "    parameters.put(\"incidenceAngleForSigma0\", \"Use projected local incidence angle from DEM\")\n",
    "    parameters.put(\"incidenceAngleForGamma0\", \"Use projected local incidence angle from DEM\")\n",
    "    parameters.put(\"auxFile\", \"Latest Auxiliary File\")\n",
    "    return GPF.createProduct(\"Terrain-Correction\", parameters, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e535897d-d216-4859-90b3-c366b784aac2",
   "metadata": {},
   "source": [
    "\n",
    "## Data for calculation\n",
    "### Images along the path\n",
    " Description:\n",
    " This script processes Sentinel-1 SAR data for interferometric analysis. It performs the following steps:\n",
    "\n",
    " 1. Define paths to Sentinel-1 SLC (Single Look Complex) data files.\n",
    " 2. Read the data from the specified files.\n",
    " 3. Split the TOPSAR data of both master and slave images into subswaths (burst 1 to 9).\n",
    " 4. Apply orbit files to correct for precise orbit information.\n",
    " 5. Perform back-geocoding to correct geometric distortions induced by satellite motion.\n",
    " 6. Calculate enhanced spectral diversity to improve coherence estimation.\n",
    " 7. Generate interferograms by computing the phase difference between master and slave images.\n",
    " 8. Deburst the TOPSAR data to remove burst synchronization artifacts.\n",
    " 9. Perform terrain correction to project the data onto a common coordinate reference system (CRS).\n",
    " 10. Save the terrain-corrected product in BEAM-DIMAP format.\n",
    "\n",
    " Usage:\n",
    " Users need to specify the paths to the input Sentinel-1 SLC data files (filename_1 and filename_2).\n",
    " The script then processes these files sequentially to perform the mentioned steps.\n",
    " Finally, it saves the terrain-corrected product to the specified output filename.\n",
    "\n",
    " Note:\n",
    " This script assumes the availability of SNAP (Sentinel Application Platform) toolbox functions for SAR data processing.\n",
    " Users should have SNAP installed and configured to use the provided functions like TOPSAR split, back-geocoding, etc.\n",
    " Additionally, users should adjust the paths and filenames according to their specific data locations and requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d319a09-46c4-46c0-ba15-e31bac181764",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename_1 = ''\n",
    "filename_2 = ''\n",
    "read1 = read(filename_1)\n",
    "read2 = read(filename_2)\n",
    "master_TOPSAR_split = TOPSAR_split1(read1, 1, 9)\n",
    "slave_TOPSAR_split = TOPSAR_split1(read2, 1, 9)\n",
    "master_orbitFile = apply_orbit_file(master_TOPSAR_split)\n",
    "slave_orbitFile = apply_orbit_file(slave_TOPSAR_split)\n",
    "backGeocoding = back_geocoding([slave_orbitFile, master_orbitFile])\n",
    "enhanced_spectral_diversity_product = enhanced_spectral_diversity(backGeocoding)\n",
    "interferogram_product = interferogram(enhanced_spectral_diversity_product)\n",
    "TOPSAR_deburst_product = topsar_deburst(interferogram_product)\n",
    "terrain_correction_product = terrain_correction(TOPSAR_deburst_product, \"EPSG:32631\")\n",
    "filename = \"\"\n",
    "write(terrain_correction_product, filename, \"BEAM-DIMAP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ac630-f4a6-450f-b4fc-8cabdff227b8",
   "metadata": {},
   "source": [
    "## Merging and Processing Sentinel-1 SAR Data\n",
    "This Python script performs data merging and processing tasks on Sentinel-1 Synthetic Aperture Radar (SAR) data obtained from the Alaska Satellite Facility (ASF). Below is a breakdown of the script's functionalities:\n",
    "### Merging CSV Files:\n",
    "The script reads two CSV files containing metadata obtained from the ASF data pool. These CSV files are merged together to consolidate the metadata information.\n",
    "### Generating File Paths:\n",
    "A function `change_name()` is defined to convert the granule names into corresponding file paths. It extracts the date information from the granule names and constructs the file paths accordingly.\n",
    "### Extracting Date Information:\n",
    "The script extracts the date from the granule names and converts it into a datetime format for sorting and further processing.\n",
    "### Sorting Data:\n",
    "The data is sorted based on the extracted date information to ensure chronological order.\n",
    "### Saving Processed Data:\n",
    "The processed data, consisting of file paths and dates, is saved to a new CSV file.\n",
    "This script streamlines the initial data processing steps required for further analysis of Sentinel-1 SAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging two csv from Alaska Facility \n",
    "df1 = pd.read_csv('')\n",
    "df2 = pd.read_csv('')\n",
    "data = pd.concat([df1, df2], ignore_index=True)\n",
    "column = data['Granule Name']\n",
    "\n",
    "def change_name(name):\n",
    "    date = name.split('_')[5]\n",
    "    year = date[:4]\n",
    "    month = date[4:6]\n",
    "    day = date[6:8]\n",
    "    new_name = f'/{year}/{month}/{day}/{name}.SAFE'\n",
    "    return new_name\n",
    "df = pd.DataFrame({'Granule Name': column, 'Path': column.apply(change_name)})\n",
    "df['Date'] = df['Granule Name'].str.extract(r'_(\\d{8})T')[0]\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d', errors='coerce')\n",
    "df = df.sort_values(by='Date')\n",
    "df.to_csv('', columns=['Path', 'Date'], index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0765c-7d5e-4e84-9f9a-2dbe870a6805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    rows = list(csv_reader)\n",
    "\n",
    "for i in range(0, len(rows) - 1):\n",
    "    path1, date1 = rows[i] \n",
    "    path2, date2 = rows[i + 1] \n",
    "\n",
    "    date1 = datetime.strptime(date1, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
    "    date2 = datetime.strptime(date2, \"%Y-%m-%d\").strftime(\"%Y%m%d\")\n",
    "\n",
    "    filename_1 = path1\n",
    "    filename_2 = path2\n",
    "    read1 = read(filename_1)\n",
    "    read2 = read(filename_2)\n",
    "\n",
    "    master_TOPSAR_split = TOPSAR_split1(read1, 1, 9)\n",
    "    slave_TOPSAR_split = TOPSAR_split1(read2, 1, 9)\n",
    "    print(\"TOPSAR split\")\n",
    "\n",
    "    master_orbitFile = apply_orbit_file(master_TOPSAR_split)\n",
    "    slave_orbitFile = apply_orbit_file(slave_TOPSAR_split)\n",
    "    print(\"Apply orbit file\")\n",
    "\n",
    "    backGeocoding = back_geocoding([slave_orbitFile, master_orbitFile])\n",
    "    print(\"Back geocoding\")\n",
    "\n",
    "    enhanced_spectral_diversity_product = enhanced_spectral_diversity(backGeocoding)\n",
    "    print(\"Enhanced spectral diversity\")\n",
    "\n",
    "    interferogram_product = interferogram(enhanced_spectral_diversity_product)\n",
    "    print(\"Interferogram\")\n",
    "\n",
    "    TOPSAR_deburst_product = topsar_deburst(interferogram_product)\n",
    "    print(\"TOPSAR deburst\")\n",
    "\n",
    "    terrain_correction_product = terrain_correction(TOPSAR_deburst_product, \"EPSG:32631\")\n",
    "    print(\"Terrain correction\")\n",
    "\n",
    "    output_filename = \"\" + date1 + \"_\" + date2\n",
    "    write(terrain_correction_product, output_filename, \"BEAM-DIMAP\")\n",
    "    print(\"Write\")\n",
    "    \n",
    "\n",
    "    read1.dispose()\n",
    "    read2.dispose()\n",
    "    master_TOPSAR_split.dispose()\n",
    "    slave_TOPSAR_split.dispose()\n",
    "    master_orbitFile.dispose()\n",
    "    slave_orbitFile.dispose()\n",
    "    backGeocoding.dispose()\n",
    "    enhanced_spectral_diversity_product.dispose()\n",
    "    interferogram_product.dispose()\n",
    "    TOPSAR_deburst_product.dispose()\n",
    "    terrain_correction_product.dispose()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
